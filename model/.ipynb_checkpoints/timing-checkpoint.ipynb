{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfab5f84",
   "metadata": {},
   "source": [
    "# Measuring the time to maximum CV\n",
    "### Params from https://ars.els-cdn.com/content/image/1-s2.0-S2211124716311986-mmc2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47621837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import lmfit\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "from scipy.special import i0 as I0\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f11fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce805f",
   "metadata": {},
   "source": [
    "## Fitting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff17b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_function(x, mu, kappa, fmax, bsl):\n",
    "    # Von Mises, with kappa the concentration, mu the location, I0 Bessel order 0\n",
    "    # fmax the firing rate at pref ori, bsl the min firing rate (not the baseline, which was substracted) \n",
    "    tf = np.exp((kappa)*np.cos((x-mu)))#/(2*np.pi*I0(kappa))\n",
    "    tf = norm_data(tf)\n",
    "    tf *= fmax\n",
    "    tf += bsl\n",
    "    return tf\n",
    "\n",
    "def norm_data(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))   \n",
    "\n",
    "def fit_tc(array, init_kappa):\n",
    "    x = np.linspace(-np.pi, np.pi, len(array))\n",
    "    y = array\n",
    "    \n",
    "    mod = Model(tuning_function)\n",
    "    pars = Parameters()\n",
    "    pars.add_many(('mu', 0, False, 0., np.pi),\n",
    "                  ('kappa', init_kappa, True,  .1, 60.),\n",
    "                  ('fmax', np.max(array), False, 0.01, np.max(array)),\n",
    "                 ('bsl', np.min(array), False, 0.0, np.max(array)))\n",
    "\n",
    "    out = mod.fit(y, pars, x=x, nan_policy='omit')\n",
    "\n",
    "    return out.best_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e803cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nakarushton(x, rmax, c50, b, n):\n",
    "    nkr = b + (rmax-b) * ((x**n) / (x**n + c50**n))\n",
    "    return nkr\n",
    "\n",
    "def fit_nkr(array) :\n",
    "    x = np.linspace(0, 1, len(array))\n",
    "    y = np.asarray(array)\n",
    "    \n",
    "    mod = Model(nakarushton)\n",
    "    pars = Parameters()\n",
    "    \n",
    "    pars.add_many(('rmax',  np.max(y), True,  0.0,  1.), # TODO maybe move back to 200 as max\n",
    "              ('c50', .5, True,  0.001, 1.),\n",
    "              ('b', y.min(), True, 0, .8),\n",
    "              ('n', 2., True,  1., 100.))\n",
    "    '''pars.add_many(('rmax',  np.max(y), True,  0.0,  2.),\n",
    "              ('c50', .5, True,  0.001, 10.),\n",
    "              ('b', y[0], True, y[0] * .1 + .001, y[-1] * 2 ),\n",
    "              ('n', 5., True,  1., 250.))'''\n",
    "    \n",
    "    out = mod.fit(y, pars, x=x, nan_policy='omit', max_nfev = 2000)\n",
    "    return out.best_values, np.abs(1-out.residual.var() / np.var(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb5659",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87191f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_data(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c63522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cirvar(arr) :\n",
    "    cv_thetas = np.linspace(-np.pi, np.pi, len(arr))\n",
    "    R = np.sum(arr* np.exp(2j*cv_thetas) / np.sum(arr))\n",
    "    cv = 1 - np.abs(np.real(R))\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d48f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa_to_hwhh(kappa) :\n",
    "    # # See equation seven https://academic.oup.com/cercor/article/13/3/225/355481#5079220\n",
    "    # Only works for kappa > 0.3467\n",
    "    #hwhh = .5*np.arccos(1+ np.log((1+np.exp(-2*kappa))/2)/kappa)\n",
    "    #hwhh = hwhh * 180 / np.pi\n",
    "    #hwhh = np.arccos((np.log(.5) + kappa) / kappa) * 180 / np.pi\n",
    "    hwhh = .5 * np.arccos( (np.log(.5)+kappa)/kappa) * 180 /np.pi\n",
    "    return hwhh\n",
    "\n",
    "def hwhh_to_btheta(hwhh) :\n",
    "    # Quoth https://github.com/NeuralEnsemble/MotionClouds/blob/master/MotionClouds/MotionClouds.py#L246\n",
    "    # HWHH = np.sqrt(2*Bt**2*np.log(2))\n",
    "    # HWHH**2 = 2*Bt**2*np.log(2)\n",
    "    # (HWHH**2)/2 = Bt**2*np.log(2)\n",
    "    # (HWHH**2)/(2*np.log(2)) = Bt**2\n",
    "    # Bt = np.sqrt((HWHH**2)/(2*np.log(2)))\n",
    "    bt = hwhh**2\n",
    "    bt = bt /2\n",
    "    bt = bt/np.log(2)\n",
    "    bt = np.sqrt(bt)\n",
    "    return bt # in degrees, if the input is in degree\n",
    "\n",
    "def kappa_to_btheta(kappa) :\n",
    "    hwhh = kappa_to_hwhh(kappa)\n",
    "    btheta = hwhh_to_btheta(hwhh)\n",
    "    return hwhh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5562bf51",
   "metadata": {},
   "source": [
    "## Simulator functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9f99c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kernel(kappae, kappai) :\n",
    "    # making the probabilistic connection patterns\n",
    "    exc_prob = tuning_function(orientation_space, 0, kappae, 1, 0)\n",
    "    exc_prob /= np.sum(exc_prob)\n",
    "    inh_prob = tuning_function(orientation_space, 0, kappai, 1, 0)\n",
    "    inh_prob /= np.sum(inh_prob)\n",
    "    \n",
    "    return exc_prob, inh_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b80af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(thetas, kappa_input, \n",
    "             Je, Ji, kappae, kappai, Jlgn, kappa_lgn,\n",
    "             duration, n, \n",
    "             idx_recorded_neuron,\n",
    "             do_RF = False, return_time = False) :\n",
    "    '''\n",
    "    This is a wrapper around the single_simulation function, which allows to run multiple \n",
    "    sims with different theta_input, in order to build a single neuron TC\n",
    "    \n",
    "    A better way would be to record all output possible for all neurons and average out but \n",
    "    that's for later :)\n",
    "    '''\n",
    "    \n",
    "    single_neuron_fr = []\n",
    "    if return_time : all_outputs = []\n",
    "    for itheta, theta in enumerate(thetas) :\n",
    "        output = single_simulation(mu_input = theta, kappa_input = kappa_input,\n",
    "                                 Je = Je, Ji = Ji, kappae = kappae, kappai = kappai,\n",
    "                                 Jlgn = Jlgn, kappa_lgn = kappa_lgn,\n",
    "                                 duration = duration, n = n, do_RF = do_RF)\n",
    "        single_neuron_fr.append(output['model_outputs'][-1, idx_recorded_neuron])\n",
    "        if return_time : all_outputs.append(output)\n",
    "        \n",
    "    output['single_neuron_fr'] = single_neuron_fr\n",
    "    if not return_time :\n",
    "        del output['mu_inputs'] #irrelevant, this is a single run's theta, so can only indice confusion\n",
    "        del output['model_outputs'] #simpler\n",
    "        del output['V'] #simpler\n",
    "        return output\n",
    "    else :\n",
    "        del output['model_inputs']\n",
    "        del output['V'] #simpler\n",
    "        print(all_outputs[0])\n",
    "        return np.asarray(all_outputs[N_thetas//2], dtype = np.float8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "602ef9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_simulation(mu_input, kappa_input, \n",
    "                     Je, Ji, kappae, kappai, Jlgn, kappa_lgn,\n",
    "                     duration, n, do_RF = False) :\n",
    "    \n",
    "    output = {'mu_input' : mu_input, 'kappa_input' : kappa_input,\n",
    "              'Je' : Je, 'Ji' : Ji, 'kappae' : kappae, 'kappai' : kappai,\n",
    "              'Jlgn' : Jlgn, 'kappa_lgn' : kappa_lgn,\n",
    "              'duration' : duration, 'n' : n, 'do_RF' : do_RF}\n",
    "    \n",
    "    # Initializes the array of inputs\n",
    "    model_inputs = tuning_function(orientation_space,mu_input, \n",
    "                                  kappa_input, 1,0)\n",
    "    \n",
    "    if do_RF :\n",
    "        # Multiplies the \"LGN\" input with a receptive field\n",
    "        RF = tuning_function(orientation_space, mu_input, kappa_lgn, 1, 0)\n",
    "        model_inputs *= RF\n",
    "    \n",
    "    # Reshaping\n",
    "    model_inputs = np.repeat(model_inputs, duration, axis = -1)\n",
    "    model_inputs = model_inputs.reshape((n, duration)).T\n",
    "    model_inputs[:,300:] = 0 # no input after 300ms\n",
    "    \n",
    "    # Kernel of response by probability distributions\n",
    "    exc_prob, inh_prob = make_kernel(kappae, kappai)\n",
    "    kernel = exc_prob*Je - inh_prob*Ji\n",
    "    fourier_j_ctx = np.fft.fft(kernel*.5)\n",
    "\n",
    "    # Make the movie\n",
    "    model_outputs = Rrest * np.ones((duration, n))\n",
    "    \n",
    "    # Voltage of the model\n",
    "    V = Rrest / alpha * np.ones((1,n))\n",
    "    \n",
    "    # Main iteration\n",
    "    for it in range(1, duration) :\n",
    "        Vlgn = Jlgn * model_inputs[it-1,:] # Voltage of input\n",
    "\n",
    "        fourier_output = np.fft.fft(model_outputs[it-1,:])/n # transforms the output into fourier\n",
    "        Vctx = n*np.real(np.fft.ifft(fourier_j_ctx*fourier_output)) # and makes it the output\n",
    "        V = V+(-V + Vlgn + Vctx)*(dt/tau) # keeping track of membrane potentials\n",
    "\n",
    "        model_outputs[it,:] = np.round(alpha * np.maximum(V, 0)* 10000)/10000 # and rectifcation\n",
    "        \n",
    "    output['model_inputs'] = model_inputs[:10,:] # we just keep the beginning\n",
    "    output['model_outputs'] = model_outputs\n",
    "    output['V'] = V\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512e4b4",
   "metadata": {},
   "source": [
    "## Data analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c7d2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nkr_array(nkr_array, dico_bounds, r2_min = .9, verbose = True) :\n",
    "    # Filters a NKR array by a list of dictionnaries, shape of \n",
    "    # 'var' : key , 'min' : 0, 'max' : 1\n",
    "    #ilt_array = copy.copy(nkr_array)\n",
    "    \n",
    "    '''for filt in dico_bounds :\n",
    "        for i, el in enumerate(filt_array) :\n",
    "            if el['nkr_fit'][0][filt['var']] > filt['min'] :\n",
    "                if el['nkr_fit'][0][filt['var']] < filt['max'] :\n",
    "                    if el['nkr_fit'][1] >= r2_min: \n",
    "                        print(el['nkr_fit'][0]['b'])\n",
    "                        pass\n",
    "                    else :\n",
    "                        del filt_array[i]\n",
    "                else :\n",
    "                    del filt_array[i]\n",
    "            else :\n",
    "                del filt_array[i]\n",
    "        print(i)\n",
    "    if verbose : print('In size : %s -- Out size : %s' % (len(nkr_array), len(filt_array)))\n",
    "    return filt_array'''\n",
    "    lst = copy.copy(nkr_array)\n",
    "    for bounds in dico_bounds :\n",
    "        lst= [x for x in lst if bounds['min'] <= x['nkr_fit'][0][bounds['var']] <= bounds['max']]\n",
    "    lst = [x for x in lst if x['nkr_fit'][1] >= r2_min]\n",
    "    if verbose : print('In size : %s -- Out size : %s' % (len(nkr_array), len(lst)))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd505669",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a78b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kernel(Je, Ji, kappae, kappai) :\n",
    "    fig, axs = plt.subplots(figsize = (10,5), ncols = 2)\n",
    "\n",
    "    exc_prob, inh_prob = make_kernel(Je, Ji, kappae, kappai)\n",
    "    axs[0].plot(orientation_space, exc_prob)\n",
    "    axs[0].plot(orientation_space, inh_prob)\n",
    "    axs[0].set_title('Proba distribution')\n",
    "\n",
    "    axs[1].plot(exc_prob*Je - inh_prob*Ji)\n",
    "    axs[1].set_title('Cortical kernel')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f92f7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_I_O_tcs(outputs) :\n",
    "    # plots the TCs of the input and the TCs of the output\n",
    "    # Has to be organized in the length of kappa_inputs\n",
    "    fig, axs = plt.subplots(figsize = (12,5), ncols = 2)\n",
    "    cols = plt.cm.viridis(np.linspace(0, 1., len(kappa_inputs)))\n",
    "    \n",
    "    hwhh_inputs = kappa_to_hwhh(kappa_inputs)\n",
    "    for i0, _ in enumerate(outputs) :\n",
    "        # Hack of the year\n",
    "        if i0 == 0 or i0 == len(kappa_inputs)-1 or i0 == len(kappa_inputs)//2 :\n",
    "            label = '%.2f' %hwhh_inputs[i0]\n",
    "        else :\n",
    "            label = '_nolabel_' #turns out everything with an underscore is skipped\n",
    "            \n",
    "        axs[0].plot(orientation_space, outputs[i0]['model_inputs'][1,:], color = cols[i0], \n",
    "                   label = label)\n",
    "        axs[1].plot(thetas, outputs[i0]['single_neuron_fr'], color = cols[i0])\n",
    "        \n",
    "    axs[0].legend(title = 'HWHH')\n",
    "    axs[0].set_title('Input TC to the model')\n",
    "    axs[1].set_title('Output TC of the model')\n",
    "    \n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1797247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_I_O_neurometric(outputs, ax, color, label = '_nolabel_',\n",
    "                        metric = 'hwhh') :\n",
    "    y = []\n",
    "    for sim in outputs :\n",
    "        if metric == 'hwhh' :\n",
    "            kappa = fit_tc(sim['single_neuron_fr'], init_kappa = sim['kappa_input'])['kappa']\n",
    "            y.append(kappa_to_hwhh(kappa))\n",
    "        elif metric == 'cv' :\n",
    "            y.append(cirvar(sim['single_neuron_fr']))\n",
    "        \n",
    "    ax.plot(kappa_to_hwhh(kappa_inputs), y, color = color, label = label)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0960283",
   "metadata": {},
   "source": [
    "# Default parameters and a single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b69f5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 128# number of neurons\n",
    "duration = 1000 # ms\n",
    "orientation_space = np.linspace(-np.pi, np.pi, n)\n",
    "\n",
    "alpha = 10.6 #gain of voltage to FR\n",
    "Rrest = 0 # resting firing rate\n",
    "tau = 10.8 # membrane time constant (ms)\n",
    "dt = .1 # simulation step time\n",
    "\n",
    "Jlgn = 9.57\n",
    "Je, Ji = 1.71, 2.0178 # see notebook on notability for the maths\n",
    "#Je, Ji = 0,0\n",
    "kappae, kappai  = 1.59, 1.16\n",
    "kappa_lgn = 1.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecbe6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'cv' # cv or hwhh, depending on what we're measuring for the output TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c17156e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_thetas = 8 # number of oriented stims, to build a single neuron tuning curve\n",
    "offset = np.pi/8 # avoid border effects\n",
    "thetas = np.linspace(-np.pi+offset, np.pi-offset, N_thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c6f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02d56f",
   "metadata": {},
   "source": [
    "# Taking multiple Ke/Ki ratio, and seeing what is the time constant at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67274798",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scans = 200 # set this to be the same as in recurrent.ipynb, otherwise you can't relate NKR to delays\n",
    "scan_kappaes = np.linspace(.35, 7., n_scans)\n",
    "scan_kappais = np.linspace(.35, 7., n_scans)\n",
    "kappa_inputs = np.linspace(22.85, .7625, 2) # we only need two here, because we're only looking at timing and not NKR\n",
    "\n",
    "#shape is inputs, kappaes, kappais\n",
    "iter_prod = list(itertools.product(range(len(kappa_inputs)),\n",
    "                                   range(n_scans),\n",
    "                                   range(n_scans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1edacb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_load = False\n",
    "do_save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef1ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating:  76%|███████████████████      | 61080/80000 [13:21<05:17, 59.66it/s]"
     ]
    }
   ],
   "source": [
    "if not do_load and do_save :\n",
    "    output_sims = Parallel(n_jobs = -1, backend = 'multiprocessing')(delayed(simulate)(\n",
    "                        thetas = thetas, kappa_input = kappa_inputs[it[0]],\n",
    "                        Je = Je, Ji = Ji,\n",
    "                        kappae = scan_kappaes[it[1]], kappai = scan_kappais[it[2]],\n",
    "                        Jlgn = Jlgn, kappa_lgn = None, duration = duration, n = n,\n",
    "                        idx_recorded_neuron = n//2,\n",
    "                        do_RF = False, return_time = True)\n",
    "                for it in tqdm(iter_prod, desc = 'Simulating', total = len(iter_prod)))\n",
    "    \n",
    "    mid_vals_bt0, mid_vals_bt36 = [], []\n",
    "    for this_scan_kappae in tqdm(scan_kappaes, 'Re-ordering the simulations') :\n",
    "        for this_scan_kappai in scan_kappais :\n",
    "            # Filtering the outputs\n",
    "            outputs = [x for x in output_sims if x['kappae'] == this_scan_kappae and\n",
    "                                                    x['kappai'] == this_scan_kappai]\n",
    "            sorted_out = sorted(outputs, key = lambda d : d['kappa_input'], reverse = True)\n",
    "            \n",
    "            fr_array = np.zeros((kappa_inputs.shape[0],duration ))\n",
    "            for ikappa, kappa in enumerate(kappa_inputs) :\n",
    "                fr_array[ikappa] = sorted_out[ikappa]['model_outputs'][:,n//2]\n",
    "\n",
    "            fr = fr_array[0,:]\n",
    "            sought_val = np.min(fr)+(np.max(fr)-np.min(fr))/2\n",
    "            mid_vals_bt0.append(find_nearest(fr, sought_val))\n",
    "\n",
    "            fr = fr_array[-1,:]\n",
    "            sought_val = np.min(fr)+(np.max(fr)-np.min(fr))/2\n",
    "            mid_vals_bt36.append(find_nearest(fr, sought_val))\n",
    "        \n",
    "    np.save('./data/time_scans_bt0.npy', mid_vals_bt0)\n",
    "    np.save('./data/time_scans_bt36.npy', mid_vals_bt36)\n",
    "\n",
    "elif not do_save and do_load :\n",
    "    mid_vals_bt0 = np.load('./data/time_scans_bt0.npy', allow_pickle = True)\n",
    "    mid_vals_bt36 = np.load('./data/time_scans_bt36.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_prod = list(itertools.product(scan_kappaes, scan_kappais))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlating kappae/kappai\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "nlevels = 10\n",
    "vmin = 50\n",
    "vmax = duration\n",
    "\n",
    "kappaes_graph = [x[0] for x in iter_prod]\n",
    "kappais_graph = [x[1] for x in iter_prod]\n",
    "time_val = [x for x in mid_vals_bt0]\n",
    "\n",
    "img_params = np.zeros((len(scan_kappais), len(scan_kappaes)))\n",
    "count_array = np.zeros_like(img_params)\n",
    "for i, _ in enumerate(time_val) :\n",
    "    idx_kappai = np.where(scan_kappais == kappais_graph[i])[0]\n",
    "    idx_kappae = np.where(scan_kappaes == kappaes_graph[i])[0]\n",
    "    img_params[idx_kappai, idx_kappae] += time_val[i]\n",
    "    count_array[idx_kappai, idx_kappae] +=1\n",
    "img_params /= count_array # cheaptrick to make the array a mean\n",
    "\n",
    "cs = ax.contourf(img_params, levels = np.linspace(vmin, vmax, nlevels, endpoint = True), \n",
    "                cmap = plt.cm.viridis,\n",
    "               vmin = vmin, vmax = vmax, \n",
    "               origin = 'lower', zorder = 30, linewidths = 0.5)\n",
    "cs2 = ax.contour(img_params, cs.levels, colors='k', zorder = 50, origin = 'lower')\n",
    "\n",
    "cax = fig.add_axes([ax.get_position().x1+0.1, # offset from the right of the axis\n",
    "                        ax.get_position().y0+0., #bottom of the colorbar\n",
    "                        0.02, #width of the colorbar\n",
    "                        .4]) #height of the colorbar\n",
    "cb = fig.colorbar(cs, cax = cax, ticks = np.linspace(vmin, vmax, nlevels))\n",
    "cb.ax.set_yticklabels(np.round(np.linspace(vmin, vmax, nlevels), 1))\n",
    "\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "cax.set_ylabel('time to half max (ms)', rotation = 270, labelpad = 20,\n",
    "              fontsize = 20)\n",
    "cb.ax.tick_params(labelsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.savefig('./figs/imgtime_bt0.pdf', format = 'pdf', dpi = 200, bbox_inches = 'tight', transparent = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlating kappae/kappai\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "nlevels = 10\n",
    "vmin = 50\n",
    "vmax = duration\n",
    "\n",
    "\n",
    "kappaes_graph = [x[0] for x in iter_prod]\n",
    "kappais_graph = [x[1] for x in iter_prod]\n",
    "time_val = [x for x in mid_vals_bt36]\n",
    "\n",
    "img_params = np.zeros((len(scan_kappais), len(scan_kappaes)))\n",
    "count_array = np.zeros_like(img_params)\n",
    "for i, _ in enumerate(time_val) :\n",
    "    idx_kappai = np.where(scan_kappais == kappais_graph[i])[0]\n",
    "    idx_kappae = np.where(scan_kappaes == kappaes_graph[i])[0]\n",
    "    img_params[idx_kappai, idx_kappae] += time_val[i]\n",
    "    count_array[idx_kappai, idx_kappae] +=1\n",
    "img_params /= count_array # cheaptrick to make the array a mean\n",
    "\n",
    "cs = ax.contourf(img_params, levels = np.linspace(vmin, vmax, nlevels, endpoint = True), \n",
    "                cmap = plt.cm.viridis,\n",
    "               vmin = vmin, vmax = vmax, \n",
    "               origin = 'lower', zorder = 30, linewidths = 0.5)\n",
    "cs2 = ax.contour(img_params, cs.levels, colors='k', zorder = 50, origin = 'lower')\n",
    "\n",
    "\n",
    "cax = fig.add_axes([ax.get_position().x1+0.1, # offset from the right of the axis\n",
    "                        ax.get_position().y0+0., #bottom of the colorbar\n",
    "                        0.02, #width of the colorbar\n",
    "                        .4]) #height of the colorbar\n",
    "cb = fig.colorbar(cs, cax = cax, ticks = np.linspace(vmin, vmax, nlevels))\n",
    "cb.ax.set_yticklabels(np.round(np.linspace(vmin, vmax, nlevels), 1))\n",
    "\n",
    "cax.set_ylabel('time to half max (ms)', rotation = 270, labelpad = 20,\n",
    "              fontsize = 20)\n",
    "cb.ax.tick_params(labelsize = 14)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.savefig('./figs/imgtime_bt36.pdf', format = 'pdf', dpi = 200, bbox_inches = 'tight', transparent = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlating kappae/kappai\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "nlevels = 10\n",
    "vmin = -.75\n",
    "vmax = .75\n",
    "\n",
    "kappaes_graph = [x[0] for x in iter_prod]\n",
    "kappais_graph = [x[1] for x in iter_prod]\n",
    "time_val = [x for x in mid_vals_bt36]\n",
    "img_params = np.zeros((len(scan_kappais), len(scan_kappaes)))\n",
    "count_array = np.zeros_like(img_params)\n",
    "for i, _ in enumerate(time_val) :\n",
    "    idx_kappai = np.where(scan_kappais == kappais_graph[i])[0]\n",
    "    idx_kappae = np.where(scan_kappaes == kappaes_graph[i])[0]\n",
    "    img_params[idx_kappai, idx_kappae] += time_val[i]\n",
    "    count_array[idx_kappai, idx_kappae] +=1\n",
    "img_params /= count_array # cheaptrick to make the array a mean\n",
    "time_val_bt36 = np.copy(img_params)\n",
    "\n",
    "kappaes_graph = [x[0] for x in iter_prod]\n",
    "kappais_graph = [x[1] for x in iter_prod]\n",
    "time_val = [x for x in mid_vals_bt0]\n",
    "img_params = np.zeros((len(scan_kappais), len(scan_kappaes)))\n",
    "count_array = np.zeros_like(img_params)\n",
    "for i, _ in enumerate(time_val) :\n",
    "    idx_kappai = np.where(scan_kappais == kappais_graph[i])[0]\n",
    "    idx_kappae = np.where(scan_kappaes == kappaes_graph[i])[0]\n",
    "    img_params[idx_kappai, idx_kappae] += time_val[i]\n",
    "    count_array[idx_kappai, idx_kappae] +=1\n",
    "img_params /= count_array # cheaptrick to make the array a mean\n",
    "time_val_bt0 = np.copy(img_params)\n",
    "\n",
    "test_img = np.log(time_val_bt36 / time_val_bt0)\n",
    "\n",
    "cs = ax.contourf(test_img, levels = np.linspace(vmin, vmax, nlevels, endpoint = True), \n",
    "                cmap = plt.cm.viridis,\n",
    "               vmin = vmin, vmax = vmax, \n",
    "               origin = 'lower', zorder = 30, linewidths = 0.5)\n",
    "cs2 = ax.contour(test_img, cs.levels, colors='k', zorder = 50, origin = 'lower')\n",
    "\n",
    "cax = fig.add_axes([ax.get_position().x1+0.1, # offset from the right of the axis\n",
    "                        ax.get_position().y0+0., #bottom of the colorbar\n",
    "                        0.02, #width of the colorbar\n",
    "                        .4]) #height of the colorbar\n",
    "cb = fig.colorbar(cs, cax = cax, ticks = np.linspace(vmin, vmax, nlevels))\n",
    "cb.ax.set_yticklabels(np.round(np.linspace(vmin, vmax, nlevels), 1))\n",
    "\n",
    "cax.set_ylabel('time to half max (ms)', rotation = 270, labelpad = 20,\n",
    "              fontsize = 20)\n",
    "cb.ax.tick_params(labelsize = 14)\n",
    "\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.savefig('./figs/img_time_ratio.pdf', format = 'pdf', dpi = 200, bbox_inches = 'tight', transparent = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a044988",
   "metadata": {},
   "source": [
    "# Reloading the recurrent.ipynb data to link the temporality to the NKR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_ultratuned = np.load('./data/single_ultratuned.npy', allow_pickle = True)\n",
    "reload_untuned = np.load('./data/single_untuned.npy', allow_pickle = True)\n",
    "reload_tuned = np.load('./data/single_tuned.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f515cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappaes_reload, kappais_reload = [], []\n",
    "for el in reload_tuned:\n",
    "    kappaes_reload.append(el['kappae'])\n",
    "    kappais_reload.append(el['kappai'])\n",
    "kappaes_reload = np.asarray(kappaes_reload)\n",
    "kappais_reload = np.asarray(kappais_reload)\n",
    "\n",
    "all_times_bt0, all_times_bt36 = [], []\n",
    "for i, _ in enumerate(kappais_reload) :\n",
    "    idx_i = np.where(scan_kappais == kappais_reload[i])[0]\n",
    "    idx_e = np.where(scan_kappaes == kappaes_reload[i])[0]\n",
    "    all_times_bt0.append(time_val_bt0[idx_i, idx_e])\n",
    "    all_times_bt36.append(time_val_bt36[idx_i, idx_e])\n",
    "    \n",
    "print('tuned')\n",
    "print(np.percentile(all_times_bt0, 5), np.percentile(all_times_bt0, 95))\n",
    "print(np.percentile(all_times_bt36, 5), np.percentile(all_times_bt36, 95))\n",
    "\n",
    "\n",
    "kappaes_reload, kappais_reload = [], []\n",
    "for el in reload_untuned:\n",
    "    kappaes_reload.append(el['kappae'])\n",
    "    kappais_reload.append(el['kappai'])\n",
    "kappaes_reload = np.asarray(kappaes_reload)\n",
    "kappais_reload = np.asarray(kappais_reload)\n",
    "\n",
    "all_times = []\n",
    "for i, _ in enumerate(kappais_reload) :\n",
    "    idx_i = np.where(scan_kappais == kappais_reload[i])[0]\n",
    "    idx_e = np.where(scan_kappaes == kappaes_reload[i])[0]\n",
    "    all_times_bt0.append(time_val_bt0[idx_i, idx_e])\n",
    "    all_times_bt36.append(time_val_bt36[idx_i, idx_e])\n",
    "    \n",
    "print('untuned')\n",
    "print(np.percentile(all_times_bt0, 5), np.percentile(all_times_bt0, 95))\n",
    "print(np.percentile(all_times_bt36, 5), np.percentile(all_times_bt36, 95))\n",
    "\n",
    "\n",
    "kappaes_reload, kappais_reload = [], []\n",
    "for el in reload_ultratuned:\n",
    "    kappaes_reload.append(el['kappae'])\n",
    "    kappais_reload.append(el['kappai'])\n",
    "kappaes_reload = np.asarray(kappaes_reload)\n",
    "kappais_reload = np.asarray(kappais_reload)\n",
    "\n",
    "all_times = []\n",
    "for i, _ in enumerate(kappais_reload) :\n",
    "    idx_i = np.where(scan_kappais == kappais_reload[i])[0]\n",
    "    idx_e = np.where(scan_kappaes == kappaes_reload[i])[0]\n",
    "    all_times_bt0.append(time_val_bt0[idx_i, idx_e])\n",
    "    all_times_bt36.append(time_val_bt36[idx_i, idx_e])\n",
    "    \n",
    "print('ultratuned')\n",
    "print(np.percentile(all_times_bt0, 5), np.percentile(all_times_bt0, 95))\n",
    "print(np.percentile(all_times_bt36, 5), np.percentile(all_times_bt36, 95))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc48b7f97eeefcfa973ac84946cdeb32dcd8538d584fc23cdbd11e050afa8c03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
